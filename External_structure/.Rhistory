pcoa_df <- data.frame(
Sample = rownames(coordinates),  # Si tienes nombres para las muestras
PCoA1 = coordinates$PCoA1,
PCoA2 = coordinates$PCoA2
)
# Proporciones explicadas para los ejes
pc1_var <- round(proportion_explained[1] * 100, 2)
pc2_var <- round(proportion_explained[2] * 100, 2)
# Crear la gráfica en ggplot2
ggplot(pcoa_df, aes(x = PCoA1, y = PCoA2, label = Sample)) +
geom_point(color = "blue", size = 3) +  # Puntos
geom_text(vjust = 1.5, hjust = 1.5) +  # Etiquetas de las muestras
labs(
title = "PCoA Plot",
x = paste0("PCoA1 (", pc1_var, "%)"),  # Etiqueta con varianza explicada
y = paste0("PCoA2 (", pc2_var, "%)")
) +
theme_minimal()
ordination_data <- readLines("~/Downloads/ordination.txt", n = 10)
# Extraer la sección de Eigenvalores
eigvals_start <- grep("Eigvals", ordination_data) + 1
eigvals_start
ordination_data
# Extraer la sección de Eigenvalores
eigvals_start <- grep("Eigvals", ordination_data) + 1
eigvals_end <- eigvals_start + 1
eigvals <- as.numeric(unlist(strsplit(ordination_data[eigvals_start:eigvals_end], "\t")))
eigvals
# Extraer la sección de Proportion explained
proportion_start <- grep("Proportion explained", ordination_data) + 1
proportion_end <- proportion_start + 1
proportion_explained <- as.numeric(unlist(strsplit(ordination_data[proportion_start:proportion_end], "\t")))
proportion_explained
# Extraer la sección de coordenadas (Site)
site_start <- grep("Site", ordination_data) + 1
site_data <- ordination_data[site_start:length(ordination_data)]
site_matrix <- do.call(rbind, lapply(site_data, function(x) as.numeric(unlist(strsplit(x, "\t")))))
site_start
site_data
site_matrix <- do.call(rbind, lapply(site_data, function(x) as.numeric(unlist(strsplit(x, "\t")))))
# Separar los nombres de las muestras y las coordenadas
site_data_clean <- lapply(site_data, function(x) {
parts <- strsplit(x, "\t")[[1]]
sample_name <- parts[1]  # Nombre de la muestra
coords <- as.numeric(parts[-1])  # Coordenadas numéricas
return(list(sample_name = sample_name, coords = coords))
})
print(head(site_matrix))
print(sample_names)
# Extraer los nombres de las muestras en un vector
sample_names <- sapply(site_data_clean, function(x) x$sample_name)
# Extraer solo las coordenadas numéricas y combinarlas en una matriz
site_matrix <- do.call(rbind, lapply(site_data_clean, function(x) x$coords))
print(head(site_matrix))
print(sample_names)
sample_names
site_data_clean
site_data_clean
# Separar los nombres de las muestras y las coordenadas numéricas
site_data_clean <- lapply(site_data, function(x) {
parts <- strsplit(x, "\t")[[1]]  # Dividir cada fila por tabulaciones
sample_name <- parts[1]  # El primer elemento es el nombre de la muestra
coords <- as.numeric(parts[-1])  # El resto son coordenadas numéricas
return(list(sample_name = sample_name, coords = coords))
})
site_data_clean
# Usar los eigenvalores para análisis (ya extraídos)
pcoa_results <- list(
eigvals = eigvals,
proportion_explained = proportion_explained,
coordinates = site_matrix
)
# Verificar las coordenadas y los eigenvalores
print(pcoa_results$coordinates)
print(pcoa_results$eigvals)
# Asegúrate de tener las coordenadas y eigenvalores
coordinates <- as.data.frame(pcoa_results$coordinates)
colnames(coordinates) <- c("PCoA1", "PCoA2")  # Nombra los ejes
eigvals <- pcoa_results$eigvals
proportion_explained <- pcoa_results$proportion_explained
# Crear el dataframe con las coordenadas
pcoa_df <- data.frame(
Sample = rownames(coordinates),  # Si tienes nombres para las muestras
PCoA1 = coordinates$PCoA1,
PCoA2 = coordinates$PCoA2
)
# Proporciones explicadas para los ejes
pc1_var <- round(proportion_explained[1] * 100, 2)
pc2_var <- round(proportion_explained[2] * 100, 2)
# Crear la gráfica en ggplot2
ggplot(pcoa_df, aes(x = PCoA1, y = PCoA2, label = Sample)) +
geom_point(color = "blue", size = 3) +  # Puntos
geom_text(vjust = 1.5, hjust = 1.5) +  # Etiquetas de las muestras
labs(
title = "PCoA Plot",
x = paste0("PCoA1 (", pc1_var, "%)"),  # Etiqueta con varianza explicada
y = paste0("PCoA2 (", pc2_var, "%)")
) +
theme_minimal()
print(head(site_matrix))
print(sample_names)
# Separar los nombres de las muestras y las coordenadas numéricas
site_data_clean <- lapply(site_data, function(x) {
parts <- strsplit(x, "\t")[[1]]  # Dividir cada fila por tabulaciones
# Verificar que haya al menos dos elementos (nombre + coordenadas)
if (length(parts) > 1) {
sample_name <- parts[1]  # El primer elemento es el nombre de la muestra
coords <- as.numeric(parts[-1])  # El resto son coordenadas numéricas
return(list(sample_name = sample_name, coords = coords))
} else {
return(NULL)  # Si la fila no tiene suficiente información, devuelve NULL
}
})
# Filtrar posibles elementos NULL
site_data_clean <- Filter(Negate(is.null), site_data_clean)
# Extraer los nombres de las muestras
sample_names <- sapply(site_data_clean, function(x) x$sample_name)
# Extraer solo las coordenadas numéricas y combinarlas en una matriz
site_matrix <- do.call(rbind, lapply(site_data_clean, function(x) x$coords))
# Verifica los nombres de las muestras
print(sample_names)
# Verifica la matriz de coordenadas
print(head(site_matrix))
# Verifica los nombres de las muestras
print(sample_names)
site_start
grep("Site", ordination_data) + 1
ordination_data
# Extraer los datos de las coordenadas del archivo
site_data_clean <- lapply(site_data, function(x) {
# Dividir cada fila por tabulaciones
parts <- strsplit(x, "\t")[[1]]
# Verificar que haya al menos dos elementos (nombre + coordenadas)
if (length(parts) > 1) {
sample_name <- parts[1]  # El primer elemento es el nombre de la muestra
coords <- as.numeric(parts[-1])  # El resto son coordenadas numéricas
return(list(sample_name = sample_name, coords = coords))
} else {
return(NULL)  # Si la fila no tiene suficiente información, devuelve NULL
}
})
# Filtrar los posibles elementos NULL (filas vacías o incorrectas)
site_data_clean <- Filter(Negate(is.null), site_data_clean)
# Extraer los nombres de las muestras en un vector
sample_names <- sapply(site_data_clean, function(x) x$sample_name)
# Extraer solo las coordenadas numéricas y combinarlas en una matriz
site_matrix <- do.call(rbind, lapply(site_data_clean, function(x) x$coords))
# Verificar los resultados
print(sample_names)  # Deberías ver todos los nombres de muestras
print(head(site_matrix))  # Las primeras coordenadas
# Verificar los resultados
print(sample_names)  # Deberías ver todos los nombres de muestras
# Verificar el número de líneas en site_data
length(site_data)
# Verificar las primeras 10 líneas de site_data
head(site_data, 10)
# Separar los nombres de las muestras y las coordenadas numéricas
site_data_clean <- lapply(site_data, function(x) {
# Dividir cada fila por cualquier cantidad de espacios o tabulaciones
parts <- strsplit(x, "[\t]+")[[1]]
# Verificar que haya al menos dos elementos (nombre + coordenadas)
if (length(parts) > 1) {
sample_name <- parts[1]  # El primer elemento es el nombre de la muestra
coords <- as.numeric(parts[-1])  # El resto son coordenadas numéricas
return(list(sample_name = sample_name, coords = coords))
} else {
return(NULL)  # Si la fila no tiene suficiente información, devuelve NULL
}
})
# Filtrar los posibles elementos NULL (filas vacías o incorrectas)
site_data_clean <- Filter(Negate(is.null), site_data_clean)
# Extraer los nombres de las muestras
sample_names <- sapply(site_data_clean, function(x) x$sample_name)
# Extraer solo las coordenadas numéricas y combinarlas en una matriz
site_matrix <- do.call(rbind, lapply(site_data_clean, function(x) x$coords))
# Verificar los resultados
print(sample_names)  # Deberías ver todos los nombres de muestras
print(head(site_matrix))  # Las primeras coordenadas
# Verificar cuántas líneas hay en site_data
print(length(site_data))  # Deberías ver el número total de líneas
# Leer el archivo completo
ordination_data <- readLines("~/Downloads/ordination.txt")  # Cambia la ruta si es necesario
# Verificar cuántas líneas tiene el archivo
print(length(ordination_data))  # Deberías ver el número total de líneas
# Verificar las primeras líneas del archivo
print(head(ordination_data, 10))  # Muestra las primeras 10 líneas
# Separar los nombres de las muestras y las coordenadas
site_data_clean <- lapply(site_data, function(x) {
parts <- strsplit(x, "[\t]+")[[1]]  # Dividir cada fila por tabulaciones
if (length(parts) > 1) {
sample_name <- parts[1]  # Nombre de la muestra
coords <- as.numeric(parts[-1])  # Coordenadas
return(list(sample_name = sample_name, coords = coords))
} else {
return(NULL)  # Si la fila no tiene suficiente información, devuelve NULL
}
})
# Filtrar los posibles elementos NULL (filas vacías o incorrectas)
site_data_clean <- Filter(Negate(is.null), site_data_clean)
# Extraer los nombres de las muestras
sample_names <- sapply(site_data_clean, function(x) x$sample_name)
# Extraer solo las coordenadas numéricas y combinarlas en una matriz
site_matrix <- do.call(rbind, lapply(site_data_clean, function(x) x$coords))
# Verificar los resultados
print(sample_names)  # Nombres de muestras
print(head(site_matrix))  # Coordenadas
# Leer la matriz de distancias
distance_matrix <- read_tsv("~/Downloads/distance-matrix.tsv")
distance_matrix
# Leer la matriz de distancias
distance_matrix <- read_tsv("~/Downloads/distance-matrix.tsv") %>% as.data.frame()
# Leer la matriz de distancias
distance_matrix <- read_tsv("~/Downloads/distance-matrix.tsv") %>% as.data.frame()
rownames(distance_matrix) <- distance_matrix$...1
distance_matrix$...1 <- NULL
# Convertir la matriz a formato largo
melted_matrix <- melt(as.matrix(distance_matrix))
# Crear el heatmap
ggplot(melted_matrix, aes(Var1, Var2, fill = value)) +
geom_tile() +
scale_fill_gradient2(low = "blue", high = "red", mid = "white", midpoint = median(melted_matrix$value), limit = c(min(melted_matrix$value), max(melted_matrix$value)), name="Distance") +
labs(title = "Heatmap of Unweighted UniFrac Distances", x = "Samples", y = "Samples") +
theme_minimal()
# Crear el heatmap con agrupamiento
pheatmap(distance_matrix,
main = "Heatmap of Unweighted UniFrac Distances with Clustering",
color = colorRampPalette(c("blue", "white", "red"))(50),
clustering_distance_rows = "euclidean",  # Método de distancia para filas
clustering_distance_cols = "euclidean",  # Método de distancia para columnas
clustering_method = "complete",  # Método de agrupamiento
display_numbers = FALSE,  # No mostrar números en las celdas
show_rownames = TRUE,  # Mostrar nombres de filas
show_colnames = TRUE)  # Mostrar nombres de columnas
library(pheatmap)
# Crear el heatmap con agrupamiento
pheatmap(distance_matrix,
main = "Heatmap of Unweighted UniFrac Distances with Clustering",
color = colorRampPalette(c("blue", "white", "red"))(50),
clustering_distance_rows = "euclidean",  # Método de distancia para filas
clustering_distance_cols = "euclidean",  # Método de distancia para columnas
clustering_method = "complete",  # Método de agrupamiento
display_numbers = FALSE,  # No mostrar números en las celdas
show_rownames = TRUE,  # Mostrar nombres de filas
show_colnames = TRUE)  # Mostrar nombres de columnas
# Weighted
# Leer la matriz de distancias
distance_matrix <- read_tsv("~/Downloads/distance-matrix.tsv") %>% as.data.frame()
rownames(distance_matrix) <- distance_matrix$...1
distance_matrix$...1 <- NULL
# Convertir la matriz a formato largo
melted_matrix <- melt(as.matrix(distance_matrix))
# Crear el heatmap con agrupamiento
pheatmap(distance_matrix,
main = "Heatmap of Unweighted UniFrac Distances with Clustering",
color = colorRampPalette(c("blue", "white", "red"))(50),
clustering_distance_rows = "euclidean",  # Método de distancia para filas
clustering_distance_cols = "euclidean",  # Método de distancia para columnas
clustering_method = "complete",  # Método de agrupamiento
display_numbers = FALSE,  # No mostrar números en las celdas
show_rownames = TRUE,  # Mostrar nombres de filas
show_colnames = TRUE)  # Mostrar nombres de columnas
# Weighted
# Leer la matriz de distancias
distance_matrix <- read_tsv("~/Downloads/distance-matrix-2.tsv") %>% as.data.frame()
rownames(distance_matrix) <- distance_matrix$...1
distance_matrix$...1 <- NULL
# Convertir la matriz a formato largo
melted_matrix <- melt(as.matrix(distance_matrix))
# Crear el heatmap con agrupamiento
pheatmap(distance_matrix,
main = "Heatmap of Unweighted UniFrac Distances with Clustering",
color = colorRampPalette(c("blue", "white", "red"))(50),
clustering_distance_rows = "euclidean",  # Método de distancia para filas
clustering_distance_cols = "euclidean",  # Método de distancia para columnas
clustering_method = "complete",  # Método de agrupamiento
display_numbers = FALSE,  # No mostrar números en las celdas
show_rownames = TRUE,  # Mostrar nombres de filas
show_colnames = TRUE)  # Mostrar nombres de columnas
# Crear el heatmap con agrupamiento
pheatmap(distance_matrix,
main = "Heatmap of Weighted UniFrac Distances with Clustering",
color = colorRampPalette(c("blue", "white", "red"))(50),
clustering_distance_rows = "euclidean",  # Método de distancia para filas
clustering_distance_cols = "euclidean",  # Método de distancia para columnas
clustering_method = "complete",  # Método de agrupamiento
display_numbers = FALSE,  # No mostrar números en las celdas
show_rownames = TRUE,  # Mostrar nombres de filas
show_colnames = TRUE)  # Mostrar nombres de columnas
# Bray distance
# Weighted
# Leer la matriz de distancias
distance_matrix <- read_tsv("~/Downloads/distance-matrix-3.tsv") %>% as.data.frame()
rownames(distance_matrix) <- distance_matrix$...1
distance_matrix$...1 <- NULL
# Convertir la matriz a formato largo
melted_matrix <- melt(as.matrix(distance_matrix))
# Crear el heatmap con agrupamiento
pheatmap(distance_matrix,
main = "Heatmap of Weighted UniFrac Distances with Clustering",
color = colorRampPalette(c("blue", "white", "red"))(50),
clustering_distance_rows = "euclidean",  # Método de distancia para filas
clustering_distance_cols = "euclidean",  # Método de distancia para columnas
clustering_method = "complete",  # Método de agrupamiento
display_numbers = FALSE,  # No mostrar números en las celdas
show_rownames = TRUE,  # Mostrar nombres de filas
show_colnames = TRUE)  # Mostrar nombres de columnas
# Crear el heatmap con agrupamiento
pheatmap(distance_matrix,
main = "Heatmap of Bray Curtis Distances with Clustering",
color = colorRampPalette(c("blue", "white", "red"))(50),
clustering_distance_rows = "euclidean",  # Método de distancia para filas
clustering_distance_cols = "euclidean",  # Método de distancia para columnas
clustering_method = "complete",  # Método de agrupamiento
display_numbers = FALSE,  # No mostrar números en las celdas
show_rownames = TRUE,  # Mostrar nombres de filas
show_colnames = TRUE)  # Mostrar nombres de columnas
## JAccard
# Leer la matriz de distancias
distance_matrix <- read_tsv("~/Downloads/distance-matrix-4.tsv") %>% as.data.frame()
rownames(distance_matrix) <- distance_matrix$...1
distance_matrix$...1 <- NULL
# Convertir la matriz a formato largo
melted_matrix <- melt(as.matrix(distance_matrix))
# Crear el heatmap con agrupamiento
pheatmap(distance_matrix,
main = "Heatmap of Bray Curtis Distances with Clustering",
color = colorRampPalette(c("blue", "white", "red"))(50),
clustering_distance_rows = "euclidean",  # Método de distancia para filas
clustering_distance_cols = "euclidean",  # Método de distancia para columnas
clustering_method = "complete",  # Método de agrupamiento
display_numbers = FALSE,  # No mostrar números en las celdas
show_rownames = TRUE,  # Mostrar nombres de filas
show_colnames = TRUE)  # Mostrar nombres de columnas
# Crear el heatmap con agrupamiento
pheatmap(distance_matrix,
main = "Heatmap of Jaccard Distances with Clustering",
color = colorRampPalette(c("blue", "white", "red"))(50),
clustering_distance_rows = "euclidean",  # Método de distancia para filas
clustering_distance_cols = "euclidean",  # Método de distancia para columnas
clustering_method = "complete",  # Método de agrupamiento
display_numbers = FALSE,  # No mostrar números en las celdas
show_rownames = TRUE,  # Mostrar nombres de filas
show_colnames = TRUE)  # Mostrar nombres de columnas
## Taxonomy
# Leer la matriz de distancias
distance_matrix <- read_tsv("~/Downloads/metadata.tsv.tsv") %>% as.data.frame()
## Taxonomy
# Leer la matriz de distancias
distance_matrix <- read_tsv("~/Downloads/metadata.tsv") %>% as.data.frame()
## Taxonomy
# Leer la matriz de distancias
taxonomy <- read_tsv("~/Downloads/metadata.tsv") %>% as.data.frame()
rownames(taxonomy) <- taxonomy$...1
taxonomy$...1 <- NULL
taxonomy
table(taxonomy$Confidence)
summary(taxonomy$Confidence)
summary(taxonomy)
taxonomy$Confidence <- as.integer(taxonomy$Confidence)
summary(taxonomy)
View(taxonomy)
## Taxonomy
# Leer la matriz de distancias
taxonomy <- read_tsv("~/Downloads/metadata.tsv") %>% as.data.frame()
rownames(taxonomy) <- taxonomy$...1
taxonomy$...1 <- NULL
View(taxonomy)
library(EBImage)
library(reticulate)
setwd('~/Documents/GitHub/CranberryLab/External_structure/')
image <- readImage('PDF/Image_Test.jpg')
# 2. Convertir la imagen a escala de grises
gray <- channel(image, 'gray')
# 3. Invertir la imagen (si es necesario)
inverted <- 1 - gray
display(inverted, title = "Imagen Invertida")
# 4. Suavizar la imagen para reducir ruido (Filtro Gaussiano)
smoothed <- gblur(inverted, sigma = 0.5)  # Ajusta sigma según la cantidad de ruido
display(smoothed, title = "Imagen Suavizada")
# 5. Etiquetar regiones conectadas
labeled <- bwlabel(smoothed > 0.1)  # Umbral binario ajustado
display(colorLabels(labeled), title = "Regiones Etiquetadas")
# 6. Eliminar regiones pequeñas (ruido)
features <- computeFeatures.shape(labeled)
summary(features)
min_area <- 100  # Cambia según el tamaño esperado de los objetos
filtered <- rmObjects(labeled, which(features[, "s.area"] < min_area))
display(colorLabels(filtered), title = "Regiones Filtradas")
# 7. Verificar las características de las regiones filtradas
features_shape <- computeFeatures.shape(filtered)
features_moment <- computeFeatures.moment(filtered)
# Combinar ambas tablas
features_with_labels <- data.frame(
Label = as.numeric(rownames(features_shape)),  # Etiquetas de los frutos
features_shape,  # Características geométricas
s.cx = features_moment[, "m.cx"],  # Coordenada X del centroide
s.cy = features_moment[, "m.cy"]   # Coordenada Y del centroide
)
# Crear una copia de la imagen filtrada
labeled_image <- colorLabels(filtered)
# Configurar el archivo de salida
output_path <- "./frutos_etiquetados.png"
png(output_path, width = 800, height = 600)  # Ajusta el tamaño según tus necesidades
# Mostrar la imagen etiquetada con colores
display(labeled_image, method = "raster")
# Superponer etiquetas
for (i in 1:nrow(features_with_labels)) {
label <- features_with_labels$Label[i]  # Etiqueta
x <- features_with_labels$s.cx[i]  # Coordenada X del centroide
y <- features_with_labels$s.cy[i]  # Coordenada Y del centroide
# Dibujar rectángulo negro detrás del texto
rect(
x - 10, y - 10, x + 10, y + 10,
col = "black", border = NA
)
# Añadir texto en el centro del rectángulo
text(
x, y, labels = as.character(label),
col = "white", cex = 0.8, font = 2
)
}
# Guardar y cerrar el dispositivo gráfico
dev.off()
cat("Imagen guardada en:", output_path, "\n")
## Detect the bar
# Etiquetar las regiones conectadas binary <- gray < 0.5  # Ajusta el umbral según sea necesario
# Eliminar ruido (suavizar la imagen)
binary <- gray < 0.8
display(binary)
binary <- opening(binary, makeBrush(5, shape = "disc"))
labeled <- bwlabel(binary)
# Calcular características de las regiones
features_bar_mom <- computeFeatures.moment(labeled)
features_bar_shape <- computeFeatures.shape(labeled)
# Combinar ambas tablas
features_with_labels_bar <- data.frame(
Label = as.numeric(rownames(features_bar_shape)),  # Etiquetas de los frutos
features_bar_shape,  # Características geométricas
s.cx = features_bar_mom[, "m.cx"],  # Coordenada X del centroide
s.cy = features_bar_mom[, "m.cy"]   # Coordenada Y del centroide
)
# Filtrar regiones rectangulares en la parte inferior de la imagen
# Supongamos que la barra tiene un área y un perímetro grandes
bar_candidate <- which(
features_with_labels_bar[, "s.area"] > 500 &  # Área mínima de la barra
features_with_labels_bar[, "s.perimeter"] > 100 &  # Perímetro mínimo
features_with_labels_bar[, "s.radius.min"] / features_with_labels_bar[, "s.radius.max"] > 0.8  # Relación aspecto casi rectangular
)
# Identificar la región más baja en la imagen
if (length(bar_candidate) > 1) {
bar_candidate <- bar_candidate[which.max(features_with_labels_bar[bar_candidate, "s.cy"])]  # Más cercana a la parte inferior
}
# Crear la máscara de la barra roja
bar_region <- labeled == bar_candidate
# Mostrar la región detectada
display(colorLabels(bar_region), title = "Barra Roja Detectada")
# Calcular la longitud de la barra en píxeles
bar_length_pixels <- features_with_labels_bar[bar_candidate, "s.perimeter"]
labeled <- bwlabel(binary)
labeled
# Eliminar ruido (suavizar la imagen)
binary <- gray < 0.8
binary <- opening(binary, makeBrush(5, shape = "disc"))
display(binary)
features_bar_shape <- computeFeatures.shape(labeled)
features_bar_shape
features_bar_mom
features_bar_mom %>% as.data.frame()
library(tidyverse)
features_bar_mom %>% as.data.frame()
features_bar_mom %>% as.data.frame() %>%
select(m.eccentricity)
features_bar_mom %>% as.data.frame() %>%
select(m.eccentricity) %>% summary
## Connect python
use_virtualenv("myenv_ext/")  # Cambia "mi_virtualenv" por tu entorno
py_config()
# Call cv2
cv2 <- import('cv2')
np <- import('numpy')
# Leer la imagen
img <- cv2$imread('PDF/Image_Test.jpg')
gray = cv2$cvtColor(img, cv2.COLOR_BGR2GRAY)
gray = cv2$cvtColor(img, cv2$COLOR_BGR2GRAY)
# Leer la imagen
img <- cv2$imread('PDF/Image_Test.jpg')
gray = cv2$cvtColor(img, cv2$COLOR_BGR2GRAY)
gray = cv2$cvtColor(img, cv2$COLOR_BGR2GRAY, dtype = np$uint8)
gray <- cv2$cvtColor(img, cv2$COLOR_BGR2GRAY, dtype = np$uint8)
if (is.null(img)) {
stop("La imagen no se pudo cargar. Verifica la ruta del archivo.")
}
# Leer la imagen
img <- cv2$imread('PDF/Image_Test.jpg')
if (is.null(img)) {
stop("La imagen no se pudo cargar. Verifica la ruta del archivo.")
}
gray <- cv2$cvtColor(img, cv2$COLOR_BGR2GRAY, dtype = np$uint8)
print(dim(img))  # Dimensiones de la imagen
print(typeof(img))  # Tipo de datos de la imagen
# Normalizar los valores de la imagen al rango [0, 255]
img <- (img - min(img)) / (max(img) - min(img)) * 255
# Convertir a enteros sin signo (uint8)
img <- as.integer(img)
# Aplicar la conversión a escala de grises
gray <- cv2$cvtColor(img, cv2$COLOR_BGR2GRAY)
# Convertir la matriz de R a un array de NumPy
np <- import("numpy")
img_np <- np$array(img, dtype = "uint8")  # Convertir a tipo uint8
# Convertir a escala de grises
cv2 <- import("cv2")
gray <- cv2$cvtColor(img_np, cv2$COLOR_BGR2GRAY)
