print(sample_names)  # Deberías ver todos los nombres de muestras
print(head(site_matrix))  # Las primeras coordenadas
# Verificar cuántas líneas hay en site_data
print(length(site_data))  # Deberías ver el número total de líneas
# Leer el archivo completo
ordination_data <- readLines("~/Downloads/ordination.txt")  # Cambia la ruta si es necesario
# Verificar cuántas líneas tiene el archivo
print(length(ordination_data))  # Deberías ver el número total de líneas
# Verificar las primeras líneas del archivo
print(head(ordination_data, 10))  # Muestra las primeras 10 líneas
# Separar los nombres de las muestras y las coordenadas
site_data_clean <- lapply(site_data, function(x) {
parts <- strsplit(x, "[\t]+")[[1]]  # Dividir cada fila por tabulaciones
if (length(parts) > 1) {
sample_name <- parts[1]  # Nombre de la muestra
coords <- as.numeric(parts[-1])  # Coordenadas
return(list(sample_name = sample_name, coords = coords))
} else {
return(NULL)  # Si la fila no tiene suficiente información, devuelve NULL
}
})
# Filtrar los posibles elementos NULL (filas vacías o incorrectas)
site_data_clean <- Filter(Negate(is.null), site_data_clean)
# Extraer los nombres de las muestras
sample_names <- sapply(site_data_clean, function(x) x$sample_name)
# Extraer solo las coordenadas numéricas y combinarlas en una matriz
site_matrix <- do.call(rbind, lapply(site_data_clean, function(x) x$coords))
# Verificar los resultados
print(sample_names)  # Nombres de muestras
print(head(site_matrix))  # Coordenadas
# Leer la matriz de distancias
distance_matrix <- read_tsv("~/Downloads/distance-matrix.tsv")
distance_matrix
# Leer la matriz de distancias
distance_matrix <- read_tsv("~/Downloads/distance-matrix.tsv") %>% as.data.frame()
# Leer la matriz de distancias
distance_matrix <- read_tsv("~/Downloads/distance-matrix.tsv") %>% as.data.frame()
rownames(distance_matrix) <- distance_matrix$...1
distance_matrix$...1 <- NULL
# Convertir la matriz a formato largo
melted_matrix <- melt(as.matrix(distance_matrix))
# Crear el heatmap
ggplot(melted_matrix, aes(Var1, Var2, fill = value)) +
geom_tile() +
scale_fill_gradient2(low = "blue", high = "red", mid = "white", midpoint = median(melted_matrix$value), limit = c(min(melted_matrix$value), max(melted_matrix$value)), name="Distance") +
labs(title = "Heatmap of Unweighted UniFrac Distances", x = "Samples", y = "Samples") +
theme_minimal()
# Crear el heatmap con agrupamiento
pheatmap(distance_matrix,
main = "Heatmap of Unweighted UniFrac Distances with Clustering",
color = colorRampPalette(c("blue", "white", "red"))(50),
clustering_distance_rows = "euclidean",  # Método de distancia para filas
clustering_distance_cols = "euclidean",  # Método de distancia para columnas
clustering_method = "complete",  # Método de agrupamiento
display_numbers = FALSE,  # No mostrar números en las celdas
show_rownames = TRUE,  # Mostrar nombres de filas
show_colnames = TRUE)  # Mostrar nombres de columnas
library(pheatmap)
# Crear el heatmap con agrupamiento
pheatmap(distance_matrix,
main = "Heatmap of Unweighted UniFrac Distances with Clustering",
color = colorRampPalette(c("blue", "white", "red"))(50),
clustering_distance_rows = "euclidean",  # Método de distancia para filas
clustering_distance_cols = "euclidean",  # Método de distancia para columnas
clustering_method = "complete",  # Método de agrupamiento
display_numbers = FALSE,  # No mostrar números en las celdas
show_rownames = TRUE,  # Mostrar nombres de filas
show_colnames = TRUE)  # Mostrar nombres de columnas
# Weighted
# Leer la matriz de distancias
distance_matrix <- read_tsv("~/Downloads/distance-matrix.tsv") %>% as.data.frame()
rownames(distance_matrix) <- distance_matrix$...1
distance_matrix$...1 <- NULL
# Convertir la matriz a formato largo
melted_matrix <- melt(as.matrix(distance_matrix))
# Crear el heatmap con agrupamiento
pheatmap(distance_matrix,
main = "Heatmap of Unweighted UniFrac Distances with Clustering",
color = colorRampPalette(c("blue", "white", "red"))(50),
clustering_distance_rows = "euclidean",  # Método de distancia para filas
clustering_distance_cols = "euclidean",  # Método de distancia para columnas
clustering_method = "complete",  # Método de agrupamiento
display_numbers = FALSE,  # No mostrar números en las celdas
show_rownames = TRUE,  # Mostrar nombres de filas
show_colnames = TRUE)  # Mostrar nombres de columnas
# Weighted
# Leer la matriz de distancias
distance_matrix <- read_tsv("~/Downloads/distance-matrix-2.tsv") %>% as.data.frame()
rownames(distance_matrix) <- distance_matrix$...1
distance_matrix$...1 <- NULL
# Convertir la matriz a formato largo
melted_matrix <- melt(as.matrix(distance_matrix))
# Crear el heatmap con agrupamiento
pheatmap(distance_matrix,
main = "Heatmap of Unweighted UniFrac Distances with Clustering",
color = colorRampPalette(c("blue", "white", "red"))(50),
clustering_distance_rows = "euclidean",  # Método de distancia para filas
clustering_distance_cols = "euclidean",  # Método de distancia para columnas
clustering_method = "complete",  # Método de agrupamiento
display_numbers = FALSE,  # No mostrar números en las celdas
show_rownames = TRUE,  # Mostrar nombres de filas
show_colnames = TRUE)  # Mostrar nombres de columnas
# Crear el heatmap con agrupamiento
pheatmap(distance_matrix,
main = "Heatmap of Weighted UniFrac Distances with Clustering",
color = colorRampPalette(c("blue", "white", "red"))(50),
clustering_distance_rows = "euclidean",  # Método de distancia para filas
clustering_distance_cols = "euclidean",  # Método de distancia para columnas
clustering_method = "complete",  # Método de agrupamiento
display_numbers = FALSE,  # No mostrar números en las celdas
show_rownames = TRUE,  # Mostrar nombres de filas
show_colnames = TRUE)  # Mostrar nombres de columnas
# Bray distance
# Weighted
# Leer la matriz de distancias
distance_matrix <- read_tsv("~/Downloads/distance-matrix-3.tsv") %>% as.data.frame()
rownames(distance_matrix) <- distance_matrix$...1
distance_matrix$...1 <- NULL
# Convertir la matriz a formato largo
melted_matrix <- melt(as.matrix(distance_matrix))
# Crear el heatmap con agrupamiento
pheatmap(distance_matrix,
main = "Heatmap of Weighted UniFrac Distances with Clustering",
color = colorRampPalette(c("blue", "white", "red"))(50),
clustering_distance_rows = "euclidean",  # Método de distancia para filas
clustering_distance_cols = "euclidean",  # Método de distancia para columnas
clustering_method = "complete",  # Método de agrupamiento
display_numbers = FALSE,  # No mostrar números en las celdas
show_rownames = TRUE,  # Mostrar nombres de filas
show_colnames = TRUE)  # Mostrar nombres de columnas
# Crear el heatmap con agrupamiento
pheatmap(distance_matrix,
main = "Heatmap of Bray Curtis Distances with Clustering",
color = colorRampPalette(c("blue", "white", "red"))(50),
clustering_distance_rows = "euclidean",  # Método de distancia para filas
clustering_distance_cols = "euclidean",  # Método de distancia para columnas
clustering_method = "complete",  # Método de agrupamiento
display_numbers = FALSE,  # No mostrar números en las celdas
show_rownames = TRUE,  # Mostrar nombres de filas
show_colnames = TRUE)  # Mostrar nombres de columnas
## JAccard
# Leer la matriz de distancias
distance_matrix <- read_tsv("~/Downloads/distance-matrix-4.tsv") %>% as.data.frame()
rownames(distance_matrix) <- distance_matrix$...1
distance_matrix$...1 <- NULL
# Convertir la matriz a formato largo
melted_matrix <- melt(as.matrix(distance_matrix))
# Crear el heatmap con agrupamiento
pheatmap(distance_matrix,
main = "Heatmap of Bray Curtis Distances with Clustering",
color = colorRampPalette(c("blue", "white", "red"))(50),
clustering_distance_rows = "euclidean",  # Método de distancia para filas
clustering_distance_cols = "euclidean",  # Método de distancia para columnas
clustering_method = "complete",  # Método de agrupamiento
display_numbers = FALSE,  # No mostrar números en las celdas
show_rownames = TRUE,  # Mostrar nombres de filas
show_colnames = TRUE)  # Mostrar nombres de columnas
# Crear el heatmap con agrupamiento
pheatmap(distance_matrix,
main = "Heatmap of Jaccard Distances with Clustering",
color = colorRampPalette(c("blue", "white", "red"))(50),
clustering_distance_rows = "euclidean",  # Método de distancia para filas
clustering_distance_cols = "euclidean",  # Método de distancia para columnas
clustering_method = "complete",  # Método de agrupamiento
display_numbers = FALSE,  # No mostrar números en las celdas
show_rownames = TRUE,  # Mostrar nombres de filas
show_colnames = TRUE)  # Mostrar nombres de columnas
## Taxonomy
# Leer la matriz de distancias
distance_matrix <- read_tsv("~/Downloads/metadata.tsv.tsv") %>% as.data.frame()
## Taxonomy
# Leer la matriz de distancias
distance_matrix <- read_tsv("~/Downloads/metadata.tsv") %>% as.data.frame()
## Taxonomy
# Leer la matriz de distancias
taxonomy <- read_tsv("~/Downloads/metadata.tsv") %>% as.data.frame()
rownames(taxonomy) <- taxonomy$...1
taxonomy$...1 <- NULL
taxonomy
table(taxonomy$Confidence)
summary(taxonomy$Confidence)
summary(taxonomy)
taxonomy$Confidence <- as.integer(taxonomy$Confidence)
summary(taxonomy)
View(taxonomy)
## Taxonomy
# Leer la matriz de distancias
taxonomy <- read_tsv("~/Downloads/metadata.tsv") %>% as.data.frame()
rownames(taxonomy) <- taxonomy$...1
taxonomy$...1 <- NULL
View(taxonomy)
# Load libraries
library(tidyverse)
# Set working directoty
setwd('~/Documents/GitHub/CranberryLab/TAcy/')
# Read data
data <- read.csv('', header = T)
# Read data
data <- read.csv('tacy_data.csv', header = T)
# Filtering data
data <-  data %>%
dplyr::filter( !(Person == 'Ree') & #
nm_520 > 0 &
nm_700 > 0)
# Do we have duplicated data?
duplicated_samples <- data %>%
summarise(n = n(), .by = c(pH, Rep, Sample_code)) %>%
filter(n > 1)
# Remove duplicated samples
data <- data[!(data$Sample_code %in% duplicated_samples$Sample_code),]
# Load Tacy concentration function
source('tacy_conc.R')
# Calculate tacy concentration
conc_data <- tacy_conc(data)
View(conc_data)
conc_data
source('.RData')
source('.Rhistory')
conc_data
View(conc_data)
# Load Tacy concentration function
source('tacy_conc.R')
# Calculate tacy concentration
conc_data <- tacy_conc(data)
# Read data
data <- read.csv('tacy_data.csv', header = T)
# Filtering data
data <-  data %>%
dplyr::filter( !(Person == 'Ree') & #
nm_520 > 0 &
nm_700 > 0)
# Do we have duplicated data?
duplicated_samples <- data %>%
summarise(n = n(), .by = c(pH, Rep, Sample_code)) %>%
filter(n > 1)
# Remove duplicated samples
data <- data[!(data$Sample_code %in% duplicated_samples$Sample_code),]
# Load Tacy concentration function
source('tacy_conc.R')
# Calculate tacy concentration
conc_data <- tacy_conc(data)
data
data
rep('2023')
data$Harvest_year <- rep('2023', times = nrow(data))
data$Harvest_year
write.csv(data, 'tacy_data.csv', quote = F, row.names = F)
# Read data
data <- read.csv('tacy_data.csv', header = T)
head(data)
# Filtering data
data <-  data %>%
dplyr::filter( !(Person == 'Ree') & #
nm_520 > 0 &
nm_700 > 0)
# Do we have duplicated data?
duplicated_samples <- data %>%
summarise(n = n(), .by = c(pH, Rep, Sample_code)) %>%
filter(n > 1)
# Remove duplicated samples
data <- data[!(data$Sample_code %in% duplicated_samples$Sample_code),]
# Load Tacy concentration function
source('tacy_conc.R')
# Calculate tacy concentration
conc_data <- tacy_conc(data)
conc_data
metadata <- read.csv('Plant_Material.csv', header = T)
head(metadata)
metadata$Sample_code <- paste(metadata$Row, metadata$Col, sep = '-')
dim(conc_data)
dim(data)
# Read data
data <- read.csv('tacy_data.csv', header = T)
dim(data)
# Filtering data
data <-  data %>%
dplyr::filter( !(Person == 'Ree') & #
nm_520 > 0 &
nm_700 > 0)
dim(data)
# Do we have duplicated data?
duplicated_samples <- data %>%
summarise(n = n(), .by = c(pH, Rep, Sample_code)) %>%
filter(n > 1)
dim(data)
# Remove duplicated samples
data <- data[!(data$Sample_code %in% duplicated_samples$Sample_code),]
dim(data)
# Read data
data <- read.csv('tacy_data.csv', header = T)
metadata <- read.csv('Plant_Material.csv', header = T)
metadata$Sample_code <- paste(metadata$Row, metadata$Col, sep = '-')
# Filtering data
data <-  data %>%
dplyr::filter( !(Person == 'Ree') & #
nm_520 > 0 &
nm_700 > 0)
# Do we have duplicated data?
duplicated_samples <- data %>%
summarise(n = n(), .by = c(pH, Rep, Sample_code)) %>%
filter(n > 1)
# Remove duplicated samples
data <- data[!(data$Sample_code %in% duplicated_samples$Sample_code),]
dim(data)
# Load Tacy concentration function
source('tacy_conc.R')
# Calculate tacy concentration
conc_data <- tacy_conc(data)
dim(data)
duplicated_samples
data
data %>%
summarise(n = n(), .by = c(pH, Rep, Sample_code))
data %>%
summarise(n = n(), .by = c(pH, Rep, Sample_code)) %>%
filter(n > 1)
# Read data
data <- read.csv('tacy_data.csv', header = T)
metadata <- read.csv('Plant_Material.csv', header = T)
metadata$Sample_code <- paste(metadata$Row, metadata$Col, sep = '-')
# Filtering data
data <-  data %>%
dplyr::filter( !(Person == 'Ree') & #
nm_520 > 0 &
nm_700 > 0)
data %>%
summarise(n = n(), .by = c(pH, Rep, Sample_code)) %>%
filter(n > 1)
# Read data
data <- read.csv('tacy_data.csv', header = T)
dim(data)
metadata <- read.csv('Plant_Material.csv', header = T)
metadata$Sample_code <- paste(metadata$Row, metadata$Col, sep = '-')
# Filtering data
data <-  data %>%
dplyr::filter( !(Person == 'Ree') & #
nm_520 > 0 &
nm_700 > 0)
dim(data)
# Do we have duplicated data?
duplicated_samples <- data %>%
summarise(n = n(), .by = c(pH, Rep, Sample_code)) %>%
filter(n > 1)
dim(duplicated_samples)
830-792
38/2
# Load libraries
library(tidyverse)
# Set working directoty
setwd('~/Documents/GitHub/CranberryLab/TAcy/')
# Read data
data <- read.csv('tacy_data.csv', header = T)
metadata <- read.csv('Plant_Material.csv', header = T)
metadata$Sample_code <- paste(metadata$Row, metadata$Col, sep = '-')
# Filtering data
data <-  data %>%
dplyr::filter( !(Person == 'Ree') & #
nm_520 > 0 &
nm_700 > 0)
# Do we have duplicated data?
duplicated_samples <- data %>%
summarise(n = n(), .by = c(pH, Rep, Sample_code, Harvest)) %>%
filter(n > 1)
dim(duplicated_samples)
dim(duplicated_samples)
# Remove duplicated samples
data <- data[!(data$Sample_code %in% duplicated_samples$Sample_code),]
# Load Tacy concentration function
source('tacy_conc.R')
# Calculate tacy concentration
conc_data <- tacy_conc(data)
dim(data)
colnames(data)
# Load Tacy concentration function
source('tacy_conc.R')
# Calculate tacy concentration
conc_data <- tacy_conc(data)
# Load Tacy concentration function
source('tacy_conc.R')
# Calculate tacy concentration
conc_data <- tacy_conc(data)
dim(data)
dim(data)
# Read data
data <- read.csv('tacy_data.csv', header = T)
colnames(data)
dim(data)
metadata <- read.csv('Plant_Material.csv', header = T)
metadata$Sample_code <- paste(metadata$Row, metadata$Col, sep = '-')
# Filtering data
data <-  data %>%
dplyr::filter( !(Person == 'Ree') & #
nm_520 > 0 &
nm_700 > 0)
dim(data)
# Do we have duplicated data?
duplicated_samples <- data %>%
summarise(n = n(), .by = c(pH, Rep, Sample_code, Harvest)) %>%
filter(n > 1)
dim(duplicated_samples)
duplicated_samples
duplicated_samples %>% unique(Sample_code)
unique(duplicated_samples$Sample_code)
12*4
48*2
# Remove duplicated samples
data <- data[!(data$Sample_code %in% duplicated_samples$Sample_code),]
dim(data)
696 + 96
conc_data
dim(conc_data)
348*2
348/2
View(conc_data)
write.csv(metadata, 'Plant_Material.csv', quote = F)
metadata <- read.csv('Plant_Material.csv', header = T)
head(metadata)
metadata
metadata$Sample_name <- metadata$X
metadata
metadata$X <- NULL
write.csv(metadata, 'Plant_Material.csv', quote = F)
metadata <- read.csv('Plant_Material.csv', header = T)
head(metadata)
write.csv(metadata, 'Plant_Material.csv', quote = F, row.names = F)
metadata <- read.csv('Plant_Material.csv', header = T)
head(metadata)
metadata$X <- NULL
write.csv(metadata, 'Plant_Material.csv', quote = F, row.names = F)
metadata <- read.csv('Plant_Material.csv', header = T)
head(metadata)
left_join(conc_data, metadata, by = 'Sample_code')
left_join(conc_data, metadata, by = 'Sample_code') %>% dim()
# Calculate tacy concentration
conc_data <- tacy_conc(data) %>% dim()
# Calculate tacy concentration
tacy_conc(data) %>% dim()
# Calculate tacy concentration
conc_data <- tacy_conc(data)
# Calculate tacy concentration
conc_data <- tacy_conc(data) %>% left_join( metadata, by = 'Sample_code')
dim(conc_data)
head(conc_data)
weight_data <- read.csv('Weight_H1_2024.csv', header = T)
head(weight_data)
table(weight_data$Sample_name %in% metadata$Sample_name)
!(weight_data$Sample_name %in% metadata$Sample_name)
weight_data[,!(weight_data$Sample_name %in% metadata$Sample_name)]
weight_data[!(weight_data$Sample_name %in% metadata$Sample_name),]
weight_data[!(toupper(weight_data$Sample_name) %in% toupper(metadata$Sample_name)),]
weight_data[(toupper(weight_data$Sample_name) %in% toupper(metadata$Sample_name)),]
table(toupper(weight_data$Sample_name) %in% toupper(metadata$Sample_name))
weight_data[(toupper(weight_data$Sample_name) %in% toupper(metadata$Sample_name)),]
metadata
metadata <- read.csv('Plant_Material.csv', header = T)
head(metadata)
metadata <- read.csv('Plant_Material.csv', header = T)
head(metadata)
metadata$Sample_code <- paste(metadata$Row, metadata$Col, sep = '-')
head(metadata)
metadata$Sample_id <- NULL
write.csv(metadata, 'Plant_Material.csv', quote = F, row.names = F)
metadata <- read.csv('Plant_Material.csv', header = T)
head(metadata)
weight_data <- read.csv('Weight_H1_2024.csv', header = T) %>% toupper(sample_name)
weight_data <- read.csv('Weight_H1_2024.csv', header = T) %>%
toupper(.$sample_name)
weight_data <- read.csv('Weight_H1_2024.csv', header = TRUE)
weight_data$Sample_name <- toupper(weight_data$Sample_name)
metadata$Sample_name <- toupper(metadata$Sample_name)
left_join(weight_data, metadata, by = 'Sample_name')
left_join(weight_data, metadata %>% select(Sample_name, Sample_code), by = 'Sample_name')
metadata %>% select(Sample_name, Sample_code
metadata %>% select(Sample_name, Sample_code)
metadata %>% select(Sample_name, Sample_code)
weight_data
weight_data <- read.csv('Weight_H1_2023.csv', header = TRUE)
weight_data$Sample_name <- toupper(weight_data$Sample_name)
metadata$Sample_name <- toupper(metadata$Sample_name)
table(weight_data$Sample_name %in% metadata$Sample_name)
weight_data[(weight_data$Sample_name %in% metadata$Sample_name),]
weight_data[!(weight_data$Sample_name %in% metadata$Sample_name),]
gsub('\\. ()', '', weight_data$Sample_name)
gsub('\\. \\(\\)', '', weight_data$Sample_name)
gsub('[\\. ()]', '', weight_data$Sample_name)
gsub('\\. ()', '', weight_data$Sample_name)
gsub('[\\. ()]', '', weight_data$Sample_name)
weight_data$Sample_name <- gsub('[\\. ()]', '', weight_data$Sample_name)
weight_data[!(weight_data$Sample_name %in% metadata$Sample_name),]
gsub('(Stevens)([1-9])', '\\10\\2', weight_data$Sample_name)
gsub('(Stevens)([1-9])', '\\1 0\\2', weight_data$Sample_name)
gsub('(Stevens)([1-9])', '\\10\\2', weight_data$Sample_name)
weight_data$Sample_name
weight_data[!(weight_data$Sample_name %in% metadata$Sample_name),]
gsub('(Stevens)([1-9])', '\\10\\2', weight_data$Sample_name)
gsub('(Stevens)([1-9])', '\\10\\2', weight_data$Sample_name)
gsub('(STEVENS)([1-9])', '\\10\\2', weight_data$Sample_name)
gsub('(STEVENS)([1-9]$)', '\\10\\2', weight_data$Sample_name)
weight_data$Sample_name <- gsub('(STEVENS)([1-9]$)', '\\10\\2', weight_data$Sample_name)
weight_data <- read.csv('Weight_H1_2023.csv', header = TRUE)
weight_data$New_name <- toupper(weight_data$Sample_name)
weight_data <- read.csv('Weight_H1_2023.csv', header = TRUE)
weight_data$New_name <- toupper(weight_data$Sample_name)
weight_data$New_name <- gsub('[\\. ()]', '', weight_data$New_name)
weight_data$New_name <- gsub('(STEVENS)([1-9]$)', '\\10\\2', weight_data$New_name)
weight_data
weight_data <- read.csv('Weight_H1_2023.csv', header = TRUE)
weight_data$Sample_name <- toupper(weight_data$Sample_name)
weight_data$Sample_name <- gsub('[\\. ()]', '', weight_data$Sample_name)
weight_data$Sample_name <- gsub('(STEVENS)([1-9]$)', '\\10\\2', weight_data$Sample_name)
weight_data[!(weight_data$Sample_name %in% metadata$Sample_name),]
write.csv(weight_data, 'Weight_H1_2023.csv', quote = F, row.names = F)
